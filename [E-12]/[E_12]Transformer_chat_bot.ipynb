{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66e326f8",
      "metadata": {
        "id": "66e326f8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "810f1788",
      "metadata": {
        "id": "810f1788"
      },
      "outputs": [],
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "    \n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "    \n",
        "    def positional_encoding(self, position, d_model):\n",
        "        # 각도 배열 생성\n",
        "        angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis,:],\n",
        "            d_model=d_model)\n",
        "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "        \n",
        "        # sin과 cosine이 교차되도록 재배열\n",
        "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "        pos_encoding = tf.transpose(pos_encoding, [1,2,0])\n",
        "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "        pos_encoding = pos_encoding[tf.newaxis,...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:,:tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8e0713dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8e0713dd",
        "outputId": "860f6b94-b188-4628-8e4f-3838ece89d2b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0,512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "85ab24cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ab24cd",
        "outputId": "5401c637-fb3f-4884-824f-0a18c0ff0254",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 50, 512)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_pos_encoding.pos_encoding.numpy().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fadb22cc",
      "metadata": {
        "id": "fadb22cc"
      },
      "source": [
        "중간 값이 최대 문장의 길이, 그 다음은 임베딩 벡터의 차원"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "17c5192f",
      "metadata": {
        "id": "17c5192f"
      },
      "outputs": [],
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "    matmul_qk = tf.matmul(query,key,transpose_b=True)\n",
        "    \n",
        "    # 가중치 정규화\n",
        "    depth = tf.cast(tf.shape(key)[-1],tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "    \n",
        "    # 패딩에 마스크 추가\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "        \n",
        "    # softmax 적용\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "    \n",
        "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "    return output\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0b12e4e6",
      "metadata": {
        "id": "0b12e4e6"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self,d_model,num_heads,name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        assert d_model % self.num_heads == 0\n",
        "        \n",
        "        self.depth = d_model // self.num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "    \n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "        \n",
        "        #Q, K, V에 각각 dense 적용\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "        \n",
        "        # 병렬 연산을 위한 머리를 여러개 만듦\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        \n",
        "        #스케일드 닷 프로덕트 어텐션 함수\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b933d507",
      "metadata": {
        "id": "b933d507"
      },
      "source": [
        "패딩 마스킹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d370f3cf",
      "metadata": {
        "id": "d370f3cf"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e7903928",
      "metadata": {
        "id": "e7903928"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10fa603a",
      "metadata": {
        "id": "10fa603a"
      },
      "source": [
        "padding mask test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "68cb1797",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68cb1797",
        "outputId": "eb21fb6b-d974-48a2-cefe-d279514f46eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e378f7b7",
      "metadata": {
        "id": "e378f7b7"
      },
      "source": [
        "0이 있을 때 padding mask test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "21aff457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21aff457",
        "outputId": "7dc42d18-b091-43ff-c179-d30313cd393f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[1. 1. 1. 1. 1.]\n",
            "   [1. 0. 1. 1. 1.]\n",
            "   [1. 0. 0. 1. 1.]\n",
            "   [1. 0. 0. 0. 1.]\n",
            "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a14d7169",
      "metadata": {
        "id": "a14d7169"
      },
      "source": [
        "인코더"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5fbb0e7e",
      "metadata": {
        "id": "5fbb0e7e"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    \n",
        "    # 패딩마스크\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "    \n",
        "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({\n",
        "        'query':inputs,\n",
        "        'key': inputs,\n",
        "        'value': inputs,\n",
        "        'mask': padding_mask\n",
        "    })\n",
        "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉 수행\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "    epsilon=1e-6)(inputs + attention)\n",
        "    \n",
        "    # 두 번째 서브레이어 : 2개의 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "    \n",
        "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "    epsilon=1e-6)(attention + outputs)\n",
        "    \n",
        "    return tf.keras.Model(\n",
        "    inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9e12da",
      "metadata": {
        "id": "da9e12da"
      },
      "source": [
        "인코더 층 쌓기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "61cffffa",
      "metadata": {
        "id": "61cffffa"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169dac82",
      "metadata": {
        "id": "169dac82"
      },
      "source": [
        "디코더 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eb653ce8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb653ce8",
        "outputId": "bf925428-cb8e-462b-e488-742767f12ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f727b674",
      "metadata": {
        "id": "f727b674"
      },
      "source": [
        "디코더 층을 쌓은 디코더"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b6a42e27",
      "metadata": {
        "id": "b6a42e27"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc1e82e",
      "metadata": {
        "id": "bfc1e82e"
      },
      "source": [
        "# 챗봇의 데이터 받기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bfa310cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfa310cb",
        "outputId": "0e28acc4-fa2c-4899-887e-d2e20e20ee3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "9920512/9916637 [==============================] - 0s 0us/step\n",
            "9928704/9916637 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'cornell_movie_dialogs.zip',\n",
        "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_dataset = os.path.join(\n",
        "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
        "\n",
        "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
        "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2309a3ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2309a3ef",
        "outputId": "3c5d3216-750f-47c3-9f73-1cffbce16d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000\n"
          ]
        }
      ],
      "source": [
        "# 사용할 샘플의 최대 개수\n",
        "MAX_SAMPLES = 50000\n",
        "print(MAX_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6e3a15cf",
      "metadata": {
        "id": "6e3a15cf"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    # 단어와 구두점 사이 거리 만듦\n",
        "    # \"I am a student.\" => \"I am a student .\"처럼\n",
        "    sentence = re.sub(r\"([?.!,])\",r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+',\" \", sentence)\n",
        "    # a-z, A-Z, \".\", \"?\", \"!\", \",\"를 제외한 모든 문자를 공백인 ' '로 변경\n",
        "    sentence = re.sub(r\"[^a-zA-z?.!,]+\",\" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e730fe82",
      "metadata": {
        "id": "e730fe82"
      },
      "outputs": [],
      "source": [
        "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
        "def load_conversations():\n",
        "  id2line = {}\n",
        "  with open(path_to_movie_lines, errors='ignore') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    id2line[parts[0]] = parts[4]\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  with open(path_to_movie_conversations, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "\n",
        "    for i in range(len(conversation) - 1):\n",
        "      # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
        "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "\n",
        "      if len(inputs) >= MAX_SAMPLES:\n",
        "        return inputs, outputs\n",
        "  return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3f0cb3f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f0cb3f2",
        "outputId": "65df943b-d5fe-444d-ea55-bfbbcb2d5810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000 50000\n"
          ]
        }
      ],
      "source": [
        "questions, answers = load_conversations()\n",
        "print(len(questions),len(answers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "dbffd0cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbffd0cc",
        "outputId": "c2270c98-1ef6-4a32-df14-5b80f3b952cb",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "she s not a . . . lesbian ? no . i found a picture of jared leto in one of her drawers , so i m pretty sure she s not harboring same sex tendencies .\n"
          ]
        }
      ],
      "source": [
        "print('{}'.format(questions[21]),'{}'.format(answers[21]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4badb289",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4badb289",
        "outputId": "49b08536-86b6-4bd4-f278-d33e2908e7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8bf06248",
      "metadata": {
        "id": "8bf06248"
      },
      "outputs": [],
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "275c8ca6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "275c8ca6",
        "outputId": "2ffb6de9-13d3-42c5-eb7e-76eb90cd9e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START_TOKEN의 번호 : [8335]\n",
            "END_TOKEN의 번호 : [8336]\n"
          ]
        }
      ],
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "15670311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15670311",
        "outputId": "bb79b897-47a3-4bc0-d5b1-52c7af56ecc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8337\n"
          ]
        }
      ],
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "77b27c85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77b27c85",
        "outputId": "708e50c0-95cc-4dd4-d21a-67e142519a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "START_TOKEN의 번호 : [8335]\n",
            "END_TOKEN의 번호 : [8336]\n"
          ]
        }
      ],
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ff798cb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff798cb0",
        "outputId": "012c3431-b5d2-4fc7-e705-a080c3512233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8337\n"
          ]
        }
      ],
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "573a1a53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "573a1a53",
        "outputId": "0fa2fa48-79b1-423c-da06-a4383f8160b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [60, 8, 37, 8176, 49]\n",
            "정수 인코딩 후의 21번째 답변 샘플: [7828, 1224, 19, 61, 2, 4, 336, 10, 1596, 14, 1106, 698, 3265, 263, 16, 71, 14, 107, 2135, 901, 3, 59, 4, 23, 355, 204, 60, 8, 37, 886, 2291, 8111, 344, 1002, 5182, 4217, 342, 1]\n"
          ]
        }
      ],
      "source": [
        "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "02d6a6a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02d6a6a4",
        "outputId": "9d1e1b3c-7402-4aba-b7a8-d251962b354f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n"
          ]
        }
      ],
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 40\n",
        "print(MAX_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f63a490c",
      "metadata": {
        "id": "f63a490c"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_filter(inputs, outputs):\n",
        "    tokenized_inputs, tokenized_outputs = [], []\n",
        "    \n",
        "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "        \n",
        "        # 최대 길이 40 이하인 경우에만 데이터 셋으로 허용\n",
        "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "            tokenized_inputs.append(sentence1)\n",
        "            tokenized_outputs.append(sentence2)\n",
        "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "    return tokenized_inputs, tokenized_outputs\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e0d9ddeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0d9ddeb",
        "outputId": "6aaf8024-15ad-4b68-f5f9-743e7c26066b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8337 44092 44092\n"
          ]
        }
      ],
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print(VOCAB_SIZE, len(questions), len(answers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1e2652e1",
      "metadata": {
        "id": "1e2652e1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a3e094b0",
      "metadata": {
        "id": "a3e094b0"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "    enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "    dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "-UPow8O1n6cN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UPow8O1n6cN",
        "outputId": "5a322a11-ceaa-4ac0-fa63-6456c7bcb0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.42.63.26:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.42.63.26:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ],
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "31871d70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31871d70",
        "outputId": "1d6c8aea-3adf-408e-db40-d8b77e0f426d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3188480     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3715840     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8337)   2142609     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,046,929\n",
            "Trainable params: 9,046,929\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "92b0e36d",
      "metadata": {
        "id": "92b0e36d"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd42e2f",
      "metadata": {
        "id": "acd42e2f"
      },
      "source": [
        "커스텀된 학습률  \n",
        "학습 초기에 높였다가 이후 step이 진행됨에 따라 낮추어가며 안정적으로 수렴하게 하는 기법이 사용됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7c4c5275",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c4c5275",
        "outputId": "25155d9c-baff-48d1-ec49-30b3b6eedc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "VRLgt_gEnVl0",
      "metadata": {
        "id": "VRLgt_gEnVl0"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fd33c1ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fd33c1ab",
        "outputId": "a59120be-37a8-42e7-869b-ef6658e4bb6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3847dd3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "3847dd3e",
        "outputId": "db8ade05-f420-4119-8be8-e32d17bf75fa"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-34310199effa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[0;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_created_in_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2993\u001b[0m           raise ValueError(\n\u001b[0;32m-> 2994\u001b[0;31m               \u001b[0;34mf'Variable ({v}) was not created in the distribution strategy '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2995\u001b[0m               \u001b[0;34mf'scope of ({strategy}). It is most likely because some '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2996\u001b[0m               \u001b[0;34m'layers, model, or optimizer was being created outside the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable (<tf.Variable 'embedding/embeddings:0' shape=(8337, 256) dtype=float32, numpy=\narray([[-8.08537006e-04, -4.88410145e-03, -1.79052576e-02, ...,\n        -1.90505628e-02,  1.45226978e-02, -3.24189663e-02],\n       [ 4.49209986e-03, -3.23084518e-02, -3.98708656e-02, ...,\n         2.27481164e-02, -1.53629947e-02, -4.22342792e-02],\n       [-2.95981392e-02,  3.89131792e-02, -5.81120048e-03, ...,\n        -1.08368732e-02, -1.09669873e-02,  4.48836610e-02],\n       ...,\n       [-3.14649828e-02,  5.65540791e-03, -9.93832946e-05, ...,\n         3.46329696e-02,  1.73608214e-03,  1.00821741e-02],\n       [-2.40446208e-03,  3.71998101e-02,  3.90031980e-03, ...,\n        -1.07005714e-02,  2.96863765e-02,  2.81572808e-02],\n       [ 2.56868452e-02, -9.68487468e-03, -3.42644267e-02, ...,\n        -1.19570615e-02,  3.03483196e-02,  3.06930784e-02]], dtype=float32)>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 object at 0x7f288c39a990>). It is most likely because some layers, model, or optimizer was being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.\nwith strategy.scope():\n  model=_create_model()\n  model.compile(...)"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9b5590e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "9b5590e9",
        "outputId": "e59117d3-df21-4c6c-bfd7-5f5b71207483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  9/689 [..............................] - ETA: 3:40 - loss: 2.9884 - accuracy: 4.4516e-05"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-2e0ccf53bdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de2b72b",
      "metadata": {
        "id": "3de2b72b"
      },
      "source": [
        "# 챗봇 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93ffe13b",
      "metadata": {
        "id": "93ffe13b"
      },
      "source": [
        "1. 새로운 입력 문장에 대해서 훈련때와 동일한 전처리\n",
        "2. 입력 문장을 토크나이징하고 START_TOKEN과 END_TOKEN을 추가\n",
        "3. 패딩 마스킹과 룩 어헤드 마스킹 계싼\n",
        "4. 디코더는 입력 시퀸스로부터 다음 단어를 예측\n",
        "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀸스에 추가하여 새로운 입력으로 사용\n",
        "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "c82be131",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c82be131",
        "outputId": "415d6663-be50-4c15-99f1-ab65a180c0f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START + tokenizer.encode(sentence) + END, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "42fe8bed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42fe8bed",
        "outputId": "51e363d4-e0ad-4e17-985e-377a92dc9f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ]
        }
      ],
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "print(\"슝=3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413f56a9",
      "metadata": {
        "id": "413f56a9",
        "outputId": "9b26b2bf-8b1e-4d68-f126-3b1bf753b1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : Where have you been?\n",
            "출력 : i m going to see my father .\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'i m going to see my father .'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_generation('Where have you been?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc591054",
      "metadata": {
        "id": "dc591054",
        "outputId": "3c1ebd03-e68f-4b15-f931-29d5a9a78e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : It's a trap\n",
            "출력 : i m not going to let you go . i m not going to let you go home and get ready . we have to go in there , don t you have to show up for time ?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'i m not going to let you go . i m not going to let you go home and get ready . we have to go in there , don t you have to show up for time ?'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_generation(\"It's a trap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e8314ae7",
      "metadata": {
        "id": "e8314ae7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "path = '/content/ChatbotData.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bce69aed",
      "metadata": {
        "id": "bce69aed"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "750267f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "750267f6",
        "outputId": "089d0728-977d-4512-a3d8-f61ff70c685f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7523ccaf-3787-414f-8d97-3a52385352b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7523ccaf-3787-414f-8d97-3a52385352b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7523ccaf-3787-414f-8d97-3a52385352b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7523ccaf-3787-414f-8d97-3a52385352b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7c256520",
      "metadata": {
        "id": "7c256520"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.strip()\n",
        "    sentence = re.sub(r\"([?.!,])\",r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-z가-힣0-9?.!,]+\",\" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "22b8590b",
      "metadata": {
        "id": "22b8590b"
      },
      "outputs": [],
      "source": [
        "df['processed_q'] = df.Q.apply(preprocess_sentence)\n",
        "df['processed_a'] = df.A.apply(preprocess_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9cd26530",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9cd26530",
        "outputId": "3d7b96c5-5ed2-49ba-9cc1-85f17492086f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'밥 사줄 친구를 찾아 보세요'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.processed_a[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "93-8QoAko0PK",
      "metadata": {
        "id": "93-8QoAko0PK"
      },
      "outputs": [],
      "source": [
        "question = df.processed_q.to_numpy()\n",
        "answer = df.processed_a.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "fde0fb2b",
      "metadata": {
        "id": "fde0fb2b"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    question + answer, target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2030090f",
      "metadata": {
        "id": "2030090f"
      },
      "outputs": [],
      "source": [
        "START, END = [tokenizer.vocab_size],[tokenizer.vocab_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "11951bbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11951bbf",
        "outputId": "ed3c3635-c21e-46ef-dd86-a1563c66577d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8359"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "VOCAB_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "da2c06af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da2c06af",
        "outputId": "6e1a6aa7-255d-40ae-e57a-79ab12b70c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8357] [8358]\n"
          ]
        }
      ],
      "source": [
        "print(START, END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "eb531553",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb531553",
        "outputId": "364e0aff-d35f-49a0-de4c-801d08023cd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[679, 740] [70, 509, 152, 3, 1]\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(question[11]),tokenizer.encode(answer[11]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f54f9f8f",
      "metadata": {
        "id": "f54f9f8f"
      },
      "outputs": [],
      "source": [
        "df['tokenized_q'] = df.processed_q.apply(tokenizer.encode)\n",
        "df['tokenized_a'] = df.processed_a.apply(tokenizer.encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9d2b2f4e",
      "metadata": {
        "id": "9d2b2f4e"
      },
      "outputs": [],
      "source": [
        "df['q_len'] = df.tokenized_q.apply(lambda x: len(x))\n",
        "df['a_len'] = df.tokenized_a.apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "27414198",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27414198",
        "outputId": "29802285-ea7b-47d2-cf03-4a02808dc991"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    11823.000000\n",
              "mean         5.481773\n",
              "std          2.500141\n",
              "min          1.000000\n",
              "25%          4.000000\n",
              "50%          5.000000\n",
              "75%          7.000000\n",
              "max         21.000000\n",
              "Name: q_len, dtype: float64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.q_len.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "7b686ae9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b686ae9",
        "outputId": "cb339260-1947-4008-b40d-a45802900bc7",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    11823.000000\n",
              "mean         5.826694\n",
              "std          2.602263\n",
              "min          1.000000\n",
              "25%          4.000000\n",
              "50%          5.000000\n",
              "75%          7.000000\n",
              "max         29.000000\n",
              "Name: a_len, dtype: float64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.a_len.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6809c12d",
      "metadata": {
        "id": "6809c12d"
      },
      "outputs": [],
      "source": [
        "# 75% 범위를 포함하고, 평균에 표준편차를 더한 값의 최대\n",
        "MAX_LENGTH = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b5ed61fe",
      "metadata": {
        "id": "b5ed61fe"
      },
      "outputs": [],
      "source": [
        "df['tokenized_q'] =  df.tokenized_q.apply(lambda x: START + x + END)\n",
        "df['tokenized_a'] = df.tokenized_a.apply(lambda x: START + x + END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "-8-u5BvSpNOA",
      "metadata": {
        "id": "-8-u5BvSpNOA"
      },
      "outputs": [],
      "source": [
        "under_max_df = df[(df.tokenized_q.apply(lambda x:len(x)) <= MAX_LENGTH) | (df.tokenized_a.apply(lambda x:len(x)) <= MAX_LENGTH)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "49a793ea",
      "metadata": {
        "id": "49a793ea"
      },
      "outputs": [],
      "source": [
        "question = tf.keras.preprocessing.sequence.pad_sequences(under_max_df.tokenized_q, maxlen=MAX_LENGTH, padding='post')\n",
        "answer = tf.keras.preprocessing.sequence.pad_sequences(under_max_df.tokenized_a,maxlen=MAX_LENGTH, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "22bc5011",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22bc5011",
        "outputId": "5a92ea17-b2f5-4586-f493-5154064593a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8359 10448 10448\n"
          ]
        }
      ],
      "source": [
        "print(VOCAB_SIZE, len(question), len(answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "40f6c110",
      "metadata": {
        "id": "40f6c110"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs':question,\n",
        "        'dec_inputs' : answer[:, :-1],\n",
        "    },\n",
        "    {\n",
        "        'outputs':answer[:, 1:]\n",
        "    },\n",
        "))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6voxehdVqiVJ",
      "metadata": {
        "id": "6voxehdVqiVJ"
      },
      "outputs": [],
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c0b3855f",
      "metadata": {
        "id": "c0b3855f"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "with strategy.scope():\n",
        "    model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "    learning_rate = CustomSchedule(D_MODEL)\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=1e-4, beta_1 =0.9, beta_2=0.98, epsilon=1e-9)\n",
        "    model.compile(optimizer=optimizer,loss=loss_function, metrics=[accuracy])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4_b4sy8YrLJE",
      "metadata": {
        "id": "4_b4sy8YrLJE"
      },
      "outputs": [],
      "source": [
        "tf.tpu.experimental.initialize_tpu_system(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "98a33ca7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98a33ca7",
        "outputId": "4e52353b-3c42-4919-df14-f9cc82bcf665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.1439 - accuracy: 0.8187\n",
            "Epoch 2/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.1309 - accuracy: 0.8198\n",
            "Epoch 3/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.1181 - accuracy: 0.8209\n",
            "Epoch 4/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.1063 - accuracy: 0.8221\n",
            "Epoch 5/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0975 - accuracy: 0.8223\n",
            "Epoch 6/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0885 - accuracy: 0.8225\n",
            "Epoch 7/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0802 - accuracy: 0.8234\n",
            "Epoch 8/30\n",
            "82/82 [==============================] - 2s 29ms/step - loss: 0.0728 - accuracy: 0.8231\n",
            "Epoch 9/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0647 - accuracy: 0.8237\n",
            "Epoch 10/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0592 - accuracy: 0.8241\n",
            "Epoch 11/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0539 - accuracy: 0.8240\n",
            "Epoch 12/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0494 - accuracy: 0.8241\n",
            "Epoch 13/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0462 - accuracy: 0.8240\n",
            "Epoch 14/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0399 - accuracy: 0.8248\n",
            "Epoch 15/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0377 - accuracy: 0.8245\n",
            "Epoch 16/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0337 - accuracy: 0.8251\n",
            "Epoch 17/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0320 - accuracy: 0.8248\n",
            "Epoch 18/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0291 - accuracy: 0.8250\n",
            "Epoch 19/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0257 - accuracy: 0.8254\n",
            "Epoch 20/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0243 - accuracy: 0.8251\n",
            "Epoch 21/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0226 - accuracy: 0.8251\n",
            "Epoch 22/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0212 - accuracy: 0.8251\n",
            "Epoch 23/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0193 - accuracy: 0.8254\n",
            "Epoch 24/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0184 - accuracy: 0.8255\n",
            "Epoch 25/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0172 - accuracy: 0.8252\n",
            "Epoch 26/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0162 - accuracy: 0.8254\n",
            "Epoch 27/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0151 - accuracy: 0.8254\n",
            "Epoch 28/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0143 - accuracy: 0.8254\n",
            "Epoch 29/30\n",
            "82/82 [==============================] - 2s 28ms/step - loss: 0.0132 - accuracy: 0.8256\n",
            "Epoch 30/30\n",
            "82/82 [==============================] - 2s 27ms/step - loss: 0.0133 - accuracy: 0.8253\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ecfb02650>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "slCA-NBX0RYv",
      "metadata": {
        "id": "slCA-NBX0RYv"
      },
      "source": [
        "epoch = 총 100회  \n",
        "learning_rate = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "99d455ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "99d455ff",
        "outputId": "dadc49be-ec11-4272-a14f-f1986ef94273",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : 적당히 해\n",
            "출력 : 사람들이 중간을 몰라요 .\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사람들이 중간을 몰라요 .'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_generation('적당히 해')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NlJSGu3X0Yi3",
      "metadata": {
        "id": "NlJSGu3X0Yi3"
      },
      "source": [
        "# 번외편"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c76b6b0a",
      "metadata": {
        "id": "c76b6b0a"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/sentiment.xlsx'\n",
        "senti_df = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "74c80d56",
      "metadata": {
        "id": "74c80d56"
      },
      "outputs": [],
      "source": [
        "senti_df['processed_q'] = senti_df['사람문장1'].apply(preprocess_sentence)\n",
        "senti_df['processed_a'] = senti_df['시스템응답1'].apply(preprocess_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "ad14f6e0",
      "metadata": {
        "id": "ad14f6e0"
      },
      "outputs": [],
      "source": [
        "senti_q = senti_df.processed_q.to_numpy()\n",
        "senti_a = senti_df.processed_a.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "a810cf6a",
      "metadata": {
        "id": "a810cf6a"
      },
      "outputs": [],
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    senti_q + senti_a, target_vocab_size=2**14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "c91edec1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c91edec1",
        "outputId": "ee56668e-5553-45d1-84fc-2d17336f295b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16217"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "7a498bc3",
      "metadata": {
        "id": "7a498bc3"
      },
      "outputs": [],
      "source": [
        "START, END = [tokenizer.vocab_size],[tokenizer.vocab_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "5303e06a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5303e06a",
        "outputId": "6f24d497-8e7a-4754-de6f-f5a2a2529c43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16219"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "VOCAB_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "63f14afd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63f14afd",
        "outputId": "2bec24ab-3c1d-4c39-db1f-e0839959de97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16217] [16218]\n"
          ]
        }
      ],
      "source": [
        "print(START, END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "5a761f54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a761f54",
        "outputId": "a1c5252c-5bf6-4395-95cc-de0bfa40ee26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[35, 343, 820, 3177, 368, 966, 3153, 5859, 54, 6265, 1602, 3264, 966, 12579, 1] [6265, 1602, 3264, 966, 3340, 2012, 1]\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(senti_q[11]),tokenizer.encode(senti_a[11]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "3d16c818",
      "metadata": {
        "id": "3d16c818"
      },
      "outputs": [],
      "source": [
        "senti_df['tokenized_q'] = senti_df.processed_q.apply(tokenizer.encode)\n",
        "senti_df['tokenized_a'] = senti_df.processed_a.apply(tokenizer.encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "96d659d1",
      "metadata": {
        "id": "96d659d1"
      },
      "outputs": [],
      "source": [
        "senti_df['q_len'] = senti_df.tokenized_q.apply(lambda x: len(x))\n",
        "senti_df['a_len'] = senti_df.tokenized_a.apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "ff1c6f07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff1c6f07",
        "outputId": "fa5ba7a1-20d6-450f-d0e9-0770f38a9051"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    40879.000000\n",
              "mean        12.321632\n",
              "std          4.582077\n",
              "min          3.000000\n",
              "25%          9.000000\n",
              "50%         12.000000\n",
              "75%         15.000000\n",
              "max         64.000000\n",
              "Name: q_len, dtype: float64"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "senti_df.q_len.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "55f032a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55f032a7",
        "outputId": "6deb4565-0c77-438d-82f3-a318618cfb11",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    40879.00000\n",
              "mean         9.01184\n",
              "std          3.34529\n",
              "min          2.00000\n",
              "25%          7.00000\n",
              "50%          8.00000\n",
              "75%         11.00000\n",
              "max         32.00000\n",
              "Name: a_len, dtype: float64"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "senti_df.a_len.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "3c547dfd",
      "metadata": {
        "id": "3c547dfd"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "43c3edbc",
      "metadata": {
        "id": "43c3edbc"
      },
      "outputs": [],
      "source": [
        "senti_df['tokenized_q'] =  senti_df.tokenized_q.apply(lambda x: START + x + END)\n",
        "senti_df['tokenized_a'] = senti_df.tokenized_a.apply(lambda x: START + x + END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "9673ed93",
      "metadata": {
        "id": "9673ed93"
      },
      "outputs": [],
      "source": [
        "under_max_df = senti_df[['tokenized_q','tokenized_a']][(senti_df['tokenized_q'].apply(lambda x: len(x)) <= MAX_LENGTH) | (senti_df['tokenized_a'].apply(lambda x: len(x))<= MAX_LENGTH) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "d7fa9d78",
      "metadata": {
        "id": "d7fa9d78"
      },
      "outputs": [],
      "source": [
        "question = tf.keras.preprocessing.sequence.pad_sequences(under_max_df.tokenized_q, maxlen=MAX_LENGTH, padding='post')\n",
        "answer = tf.keras.preprocessing.sequence.pad_sequences(under_max_df.tokenized_a,maxlen=MAX_LENGTH, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "e0445e27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0445e27",
        "outputId": "799e50c5-4179-418f-d08a-d59ca4e3e913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16219 39343 39343\n"
          ]
        }
      ],
      "source": [
        "print(VOCAB_SIZE, len(question), len(answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "af8628dc",
      "metadata": {
        "id": "af8628dc"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs':question,\n",
        "        'dec_inputs' : answer[:, :-1],\n",
        "    },\n",
        "    {\n",
        "        'outputs':answer[:, 1:]\n",
        "    },\n",
        "))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "E13HiHSrtGcp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E13HiHSrtGcp",
        "outputId": "1be08e98-dce8-495d-ecdc-0745c880411c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.42.63.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.42.63.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.42.63.26:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.42.63.26:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f8ecb4ec950>"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.tpu.experimental.initialize_tpu_system(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "4172a80d",
      "metadata": {
        "id": "4172a80d"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "with strategy.scope():\n",
        "    model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "    learning_rate = CustomSchedule(D_MODEL)\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "    1e-4, beta_1 =0.9, beta_2=0.98, epsilon=1e-9)\n",
        "    model.compile(optimizer=optimizer,loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "5eb3c302",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eb3c302",
        "outputId": "6c7ae42e-1e76-4a82-b221-7e911d2a76f1",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "308/308 [==============================] - 60s 93ms/step - loss: 4.7303 - accuracy: 0.1030\n",
            "Epoch 2/30\n",
            "308/308 [==============================] - 11s 37ms/step - loss: 3.8105 - accuracy: 0.1555\n",
            "Epoch 3/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 3.4977 - accuracy: 0.1787\n",
            "Epoch 4/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 3.3003 - accuracy: 0.1917\n",
            "Epoch 5/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 3.1463 - accuracy: 0.2018\n",
            "Epoch 6/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 3.0200 - accuracy: 0.2095\n",
            "Epoch 7/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.9106 - accuracy: 0.2167\n",
            "Epoch 8/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.8105 - accuracy: 0.2239\n",
            "Epoch 9/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.7163 - accuracy: 0.2313\n",
            "Epoch 10/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.6262 - accuracy: 0.2382\n",
            "Epoch 11/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 2.5391 - accuracy: 0.2456\n",
            "Epoch 12/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 2.4565 - accuracy: 0.2529\n",
            "Epoch 13/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 2.3766 - accuracy: 0.2598\n",
            "Epoch 14/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.2988 - accuracy: 0.2668\n",
            "Epoch 15/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 2.2240 - accuracy: 0.2741\n",
            "Epoch 16/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.1501 - accuracy: 0.2812\n",
            "Epoch 17/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.0787 - accuracy: 0.2888\n",
            "Epoch 18/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 2.0100 - accuracy: 0.2957\n",
            "Epoch 19/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.9426 - accuracy: 0.3028\n",
            "Epoch 20/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.8765 - accuracy: 0.3096\n",
            "Epoch 21/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.8107 - accuracy: 0.3177\n",
            "Epoch 22/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.7466 - accuracy: 0.3254\n",
            "Epoch 23/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.6849 - accuracy: 0.3331\n",
            "Epoch 24/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.6234 - accuracy: 0.3409\n",
            "Epoch 25/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.5637 - accuracy: 0.3494\n",
            "Epoch 26/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.5041 - accuracy: 0.3575\n",
            "Epoch 27/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 1.4456 - accuracy: 0.3660\n",
            "Epoch 28/30\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 1.3890 - accuracy: 0.3741\n",
            "Epoch 29/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.3325 - accuracy: 0.3830\n",
            "Epoch 30/30\n",
            "308/308 [==============================] - 12s 37ms/step - loss: 1.2785 - accuracy: 0.3913\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ec9f85590>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "HGayT5YU3Rcs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGayT5YU3Rcs",
        "outputId": "4b273f45-3467-4442-da72-c1998ec6e7a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0536 - accuracy: 0.6302\n",
            "Epoch 2/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0510 - accuracy: 0.6308\n",
            "Epoch 3/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0494 - accuracy: 0.6313\n",
            "Epoch 4/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0479 - accuracy: 0.6315\n",
            "Epoch 5/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0467 - accuracy: 0.6318\n",
            "Epoch 6/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0456 - accuracy: 0.6319\n",
            "Epoch 7/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0441 - accuracy: 0.6323\n",
            "Epoch 8/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0430 - accuracy: 0.6325\n",
            "Epoch 9/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0419 - accuracy: 0.6327\n",
            "Epoch 10/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0401 - accuracy: 0.6331\n",
            "Epoch 11/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0388 - accuracy: 0.6334\n",
            "Epoch 12/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0383 - accuracy: 0.6335\n",
            "Epoch 13/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0374 - accuracy: 0.6336\n",
            "Epoch 14/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0361 - accuracy: 0.6338\n",
            "Epoch 15/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0353 - accuracy: 0.6340\n",
            "Epoch 16/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0352 - accuracy: 0.6341\n",
            "Epoch 17/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0335 - accuracy: 0.6344\n",
            "Epoch 18/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0333 - accuracy: 0.6344\n",
            "Epoch 19/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0325 - accuracy: 0.6346\n",
            "Epoch 20/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0320 - accuracy: 0.6347\n",
            "Epoch 21/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0310 - accuracy: 0.6351\n",
            "Epoch 22/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0300 - accuracy: 0.6352\n",
            "Epoch 23/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0295 - accuracy: 0.6353\n",
            "Epoch 24/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0291 - accuracy: 0.6354\n",
            "Epoch 25/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0281 - accuracy: 0.6355\n",
            "Epoch 26/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0274 - accuracy: 0.6359\n",
            "Epoch 27/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0271 - accuracy: 0.6356\n",
            "Epoch 28/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0268 - accuracy: 0.6358\n",
            "Epoch 29/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0257 - accuracy: 0.6360\n",
            "Epoch 30/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0257 - accuracy: 0.6360\n",
            "Epoch 31/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0255 - accuracy: 0.6359\n",
            "Epoch 32/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0248 - accuracy: 0.6362\n",
            "Epoch 33/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0242 - accuracy: 0.6364\n",
            "Epoch 34/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0235 - accuracy: 0.6366\n",
            "Epoch 35/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0232 - accuracy: 0.6365\n",
            "Epoch 36/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0228 - accuracy: 0.6366\n",
            "Epoch 37/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0230 - accuracy: 0.6366\n",
            "Epoch 38/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0223 - accuracy: 0.6367\n",
            "Epoch 39/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0218 - accuracy: 0.6369\n",
            "Epoch 40/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0214 - accuracy: 0.6370\n",
            "Epoch 41/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0213 - accuracy: 0.6369\n",
            "Epoch 42/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0210 - accuracy: 0.6371\n",
            "Epoch 43/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0207 - accuracy: 0.6371\n",
            "Epoch 44/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0202 - accuracy: 0.6372\n",
            "Epoch 45/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0199 - accuracy: 0.6373\n",
            "Epoch 46/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0198 - accuracy: 0.6373\n",
            "Epoch 47/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0193 - accuracy: 0.6374\n",
            "Epoch 48/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0193 - accuracy: 0.6374\n",
            "Epoch 49/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0189 - accuracy: 0.6375\n",
            "Epoch 50/50\n",
            "308/308 [==============================] - 12s 38ms/step - loss: 0.0183 - accuracy: 0.6376\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ec7b883d0>"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "481b0f2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "481b0f2e",
        "outputId": "d114edf3-c28e-40af-89bb-bd5d6c5aacc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "입력 : 기분이 좋지 않아\n",
            "출력 : 기분이 좋지 않은 이유를 알 수 있을까요 ?\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'기분이 좋지 않은 이유를 알 수 있을까요 ?'"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_generation('기분이 좋지 않아')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZC7fnV72-510",
      "metadata": {
        "id": "ZC7fnV72-510"
      },
      "source": [
        "# 실험종료  \n",
        "트랜스포머로 만드는 대화형 챗봇을 시도하였다  \n",
        "대체로 모든 코드는 기존의 코드를 사용했으며, 토크나이징 과정에서는 기존 코드는 for문을 활용해서 작업을 했는데, 이 부분은 그냥 판다스로 간단하게 수정하는 작업을 했다  \n",
        "특수 문자 처리작업에서는 특별히 달라진 점은 없으나 데이터가 한국어 데이터로 달라졌기 때문에 이를 해결하기 위해 정규식에 가-힣을 추가하여 한국어 또한 포함되게끔 설정하였다  \n",
        "데이터셋을 만드는 과정에서 데이터의 적절한 MAX_LENGTH는 평균에서 표준편차 안에 드는 범위안에서 설정하여 데이터의 80%정도가 포함되게끔 설정하였다  \n",
        "모델 에포크를 하는 과정에서 가면 갈수록 러닝레이트 값이 급격하게 감소하는지 정확도가 60~70어간에서 수렴하는 듯이 멈추었기 때문에 러닝레이트를 1e-4로 바꾸고나서야 정확도를 80% 이상으로 맞출 수 있었고 정확도가 80퍼 이상으로 높아지고 난 뒤에야 비로소 말다운 말을 하는 것을 볼 수 있었다  \n",
        "이 과정에서 에포크는 약 100회정도 실시되었다  \n",
        "이후의 데이터셋을 추가로 사용해보고자 AIHUB에 있는 감성 분석 말뭉치용 데이터에서 사용자간 데이터 부분만 추출해서\n",
        "학습을 시도해보았다  \n",
        "그러나 말뭉치의 데이터 특성상 위로와 공감에 특정되어있다보니 주로 그쪽 부분에 대해서만 사람과 대화하듯 말을 할 수가 있었다  \n",
        "데이터의 힘을 다시 한번 확인했으며, 이제는 데이터 확보만 된다면 해당 분야의 챗봇은 확실하게 만들 수 있을 듯 하다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L5Cq4DMIDYub",
      "metadata": {
        "id": "L5Cq4DMIDYub"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "[E-12]Transformer_chat_bot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
